"""
é«˜è´¨é‡SoundFontæ¸²æŸ“å™¨

è´Ÿè´£å°†Petersenä½œæ›²è½¬æ¢ä¸ºé«˜è´¨é‡WAVéŸ³é¢‘æ–‡ä»¶ï¼Œè¿™æ˜¯æ•´ä¸ªç³»ç»Ÿæœ€ç»ˆè¾“å‡ºçš„æ ¸å¿ƒç»„ä»¶ã€‚
æ”¯æŒå½•éŸ³å®¤çº§åˆ«çš„éŸ³é¢‘æ¸²æŸ“ï¼Œç¡®ä¿æ•°å­¦æ¨¡å‹çš„éŸ³ä¹ç¾å­¦èƒ½å¤Ÿä»¥æœ€ä½³éŸ³è´¨å‘ˆç°ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- ç²¾ç¡®é¢‘ç‡SoundFontæ¸²æŸ“
- å¤šç§è´¨é‡çº§åˆ«æ”¯æŒ
- æ‰¹é‡éŸ³é¢‘ç”Ÿæˆ
- éŸ³æ•ˆå¤„ç†é“¾é›†æˆ
- å®æ—¶è¿›åº¦ç›‘æ§

æŠ€æœ¯ç‰¹ç‚¹ï¼š
- ä½¿ç”¨libs/ä¸­çš„FluidSynthæ¥å£è¿›è¡Œä¸“ä¸šéŸ³é¢‘åˆæˆ
- æ”¯æŒ48kHz/24bitå½•éŸ³å®¤è´¨é‡
- ç²¾ç¡®çš„Petersené¢‘ç‡è¡¥å¿
- å®Œæ•´çš„éŸ³æ•ˆå¤„ç†æµæ°´çº¿
"""

import sys
import time
import wave
import array
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass
from enum import Enum

# å¯¼å…¥numpyï¼ˆå¿…éœ€åº“ï¼‰
try:
    import numpy as np
except ImportError:
    print("âŒ NumPyåº“æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡ŒéŸ³é¢‘å¤„ç†")
    print("è¯·è¿è¡Œ: pip install numpy")
    sys.exit(1)

# æ·»åŠ libsè·¯å¾„
current_dir = Path(__file__).parent
libs_dir = current_dir.parent / "libs"
if str(libs_dir) not in sys.path:
    sys.path.insert(0, str(libs_dir))

# å¯¼å…¥libsä¸­çš„éŸ³é¢‘æ¨¡å—
try:
    from frequency_accurate import FrequencyAccuratePlayback
    from audio_effects import AdvancedAudioEffects, EffectSettings
    from expression_control import ExpressionController, ExpressionParameters
    from soundfont_manager import SoundFontManager
    from utils.constants import DEFAULT_SOUNDFONTS
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥éŸ³é¢‘æ¨¡å—å¤±è´¥: {e}")

class RenderQuality(Enum):
    """æ¸²æŸ“è´¨é‡çº§åˆ«"""
    DRAFT = "draft"           # 22kHz, 16bit, åŸºç¡€éŸ³æ•ˆ
    STANDARD = "standard"     # 44.1kHz, 16bit, æ ‡å‡†éŸ³æ•ˆ
    HIGH = "high"            # 44.1kHz, 24bit, é«˜çº§éŸ³æ•ˆ
    STUDIO = "studio"        # 48kHz, 24bit, å½•éŸ³å®¤éŸ³æ•ˆ

@dataclass
class RenderSettings:
    """æ¸²æŸ“è®¾ç½®"""
    quality: RenderQuality = RenderQuality.STANDARD
    sample_rate: int = 44100
    bit_depth: int = 16
    buffer_size: int = 512
    enable_effects: bool = True
    enable_expression: bool = True
    normalize_audio: bool = True
    fade_in_ms: int = 50
    fade_out_ms: int = 200

@dataclass
class RenderProgress:
    """æ¸²æŸ“è¿›åº¦"""
    total_notes: int = 0
    rendered_notes: int = 0
    current_measure: int = 0
    total_measures: int = 0
    elapsed_time: float = 0.0
    estimated_remaining: float = 0.0
    status: str = "å‡†å¤‡ä¸­"

class HighQualitySoundFontRenderer:
    """é«˜è´¨é‡SoundFontæ¸²æŸ“å™¨"""
    
    def __init__(self, master_studio):
        """
        åˆå§‹åŒ–æ¸²æŸ“å™¨
        
        Args:
            master_studio: PetersenMasterStudioå®ä¾‹
        """
        self.master_studio = master_studio
        
        # ä»master_studioè·å–FluidSynthæ¥å£
        self.fluidsynth = None
        self.synth = None
        self.current_soundfont_id = None
        
        # æ¸²æŸ“ç»„ä»¶
        self.freq_player = None
        self.effects = None
        self.expression = None
        self.sf_manager = None
        
        # æ¸²æŸ“çŠ¶æ€
        self.is_initialized = False
        self.current_settings = RenderSettings()
        self.render_progress = RenderProgress()
        self.is_rendering = False
        
        # éŸ³é¢‘ç¼“å†²
        self.audio_buffer = []
        self.buffer_lock = threading.Lock()
        
        # åˆå§‹åŒ–æ¸²æŸ“å™¨
        self._initialize_renderer()
    
    def _initialize_renderer(self):
        """åˆå§‹åŒ–æ¸²æŸ“å™¨"""
        try:
            # ä»master_studioè·å–å·²åˆå§‹åŒ–çš„FluidSynthæ¥å£
            if hasattr(self.master_studio, 'player') and self.master_studio.player:
                player = self.master_studio.player
                
                # è·å–FluidSynthæ ¸å¿ƒå¯¹è±¡
                self.fluidsynth = player.fluidsynth
                self.synth = player.synth
                
                if not self.fluidsynth or not self.synth:
                    print("âŒ æ— æ³•ä»master_studioè·å–FluidSynthæ¥å£")
                    return
                
                # åˆå§‹åŒ–éŸ³é¢‘å¤„ç†ç»„ä»¶
                self.freq_player = player.freq_player
                self.effects = player.effects
                self.expression = player.expression
                self.sf_manager = player.sf_manager
                
                # è·å–å½“å‰SoundFont ID
                if self.sf_manager and self.sf_manager.current_soundfont_id:
                    self.current_soundfont_id = self.sf_manager.current_soundfont_id
                
                self.is_initialized = True
                print("âœ“ é«˜è´¨é‡æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ (ä½¿ç”¨master_studioæ¥å£)")
                
            else:
                print("âŒ master_studioä¸­æœªæ‰¾åˆ°å¯ç”¨çš„æ’­æ”¾å™¨æ¥å£")
                self.is_initialized = False
                
        except Exception as e:
            print(f"âŒ æ¸²æŸ“å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_initialized = False
    
    def load_soundfont(self, soundfont_path: str) -> bool:
        """
        åŠ è½½SoundFontæ–‡ä»¶
        
        Args:
            soundfont_path: SoundFontæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        if not self.is_initialized or not self.sf_manager:
            return False
        
        try:
            # ä½¿ç”¨sf_manageråŠ è½½SoundFont
            success = self.sf_manager.load_soundfont(soundfont_path)
            
            if success:
                self.current_soundfont_id = self.sf_manager.current_soundfont_id
                print(f"âœ“ SoundFontå·²åŠ è½½: {soundfont_path}")
                return True
            else:
                print(f"âŒ SoundFontåŠ è½½å¤±è´¥: {soundfont_path}")
                return False
                
        except Exception as e:
            print(f"âŒ SoundFontåŠ è½½é”™è¯¯: {e}")
            return False
    
    def configure_quality(self, quality: RenderQuality):
        """
        é…ç½®æ¸²æŸ“è´¨é‡
        
        Args:
            quality: è´¨é‡çº§åˆ«
        """
        quality_settings = {
            RenderQuality.DRAFT: RenderSettings(
                quality=quality,
                sample_rate=22050,
                bit_depth=16,
                buffer_size=1024,
                enable_effects=False,
                enable_expression=False
            ),
            RenderQuality.STANDARD: RenderSettings(
                quality=quality,
                sample_rate=44100,
                bit_depth=16,
                buffer_size=512,
                enable_effects=True,
                enable_expression=True
            ),
            RenderQuality.HIGH: RenderSettings(
                quality=quality,
                sample_rate=44100,
                bit_depth=24,
                buffer_size=256,
                enable_effects=True,
                enable_expression=True
            ),
            RenderQuality.STUDIO: RenderSettings(
                quality=quality,
                sample_rate=48000,
                bit_depth=24,
                buffer_size=128,
                enable_effects=True,
                enable_expression=True,
                normalize_audio=True
            )
        }
        
        self.current_settings = quality_settings[quality]
        
        # æ›´æ–°FluidSynthè®¾ç½®
        if self.is_initialized and hasattr(self.fluidsynth, 'fluid_settings_setnum'):
            try:
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è®¿é—®playerçš„settingså¯¹è±¡
                player = self.master_studio.player
                if hasattr(player, 'settings') and player.settings:
                    self.fluidsynth.fluid_settings_setnum(
                        player.settings, 
                        b"synth.sample-rate", 
                        float(self.current_settings.sample_rate)
                    )
                    
                    print(f"âœ“ æ¸²æŸ“è´¨é‡å·²è®¾ç½®ä¸º: {quality.value}")
                    print(f"   é‡‡æ ·ç‡: {self.current_settings.sample_rate}Hz")
                    print(f"   ä½æ·±åº¦: {self.current_settings.bit_depth}bit")
                
            except Exception as e:
                print(f"âš ï¸ è´¨é‡è®¾ç½®æ›´æ–°è­¦å‘Š: {e}")
    
    def render_composition(self, composition, output_path: Path, 
                          quality: Optional[RenderQuality] = None) -> Optional[Path]:
        """
        æ¸²æŸ“å®Œæ•´ä½œæ›²åˆ°WAVæ–‡ä»¶
        
        Args:
            composition: ä½œæ›²å¯¹è±¡
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            quality: æ¸²æŸ“è´¨é‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Path: æˆåŠŸæ—¶è¿”å›è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.is_initialized:
            print("âŒ æ¸²æŸ“å™¨æœªåˆå§‹åŒ–")
            return None
        
        try:
            # è®¾ç½®è´¨é‡
            if quality:
                self.configure_quality(quality)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¼€å§‹æ¸²æŸ“
            self.is_rendering = True
            self.render_progress.status = "æ­£åœ¨æ¸²æŸ“..."
            
            print(f"ğŸµ å¼€å§‹æ¸²æŸ“: {output_path.name}")
            print(f"   è´¨é‡: {self.current_settings.quality.value}")
            
            # ç¡®ä¿SoundFontå·²åŠ è½½
            if not self._ensure_soundfont_loaded():
                return None
            
            # æå–ä½œæ›²æ•°æ®
            render_data = self._extract_composition_data(composition)
            if not render_data:
                print("âŒ æ— æ³•æå–ä½œæ›²æ•°æ®")
                return None
            
            # æ‰§è¡Œæ¸²æŸ“
            audio_data = self._render_audio_data(render_data)
            if audio_data is None:
                print("âŒ éŸ³é¢‘æ¸²æŸ“å¤±è´¥")
                return None
            
            # åå¤„ç†
            if self.current_settings.normalize_audio:
                audio_data = self._normalize_audio(audio_data)
            
            audio_data = self._apply_fade(audio_data)
            
            # ä¿å­˜WAVæ–‡ä»¶
            success = self._save_wav_file(audio_data, output_path)
            
            if success:
                print(f"âœ“ æ¸²æŸ“å®Œæˆ: {output_path.name}")
                print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.1f} MB")
                return output_path
            else:
                return None
                
        except Exception as e:
            print(f"âŒ æ¸²æŸ“å¤±è´¥: {e}")
            return None
        finally:
            self.is_rendering = False
            self.render_progress.status = "å®Œæˆ"
    
    def render_composition_realtime(self, composition, preview_duration: float = 10.0) -> bool:
        """
        å®æ—¶æ¸²æŸ“ä½œæ›²é¢„è§ˆ
        
        Args:
            composition: ä½œæ›²å¯¹è±¡
            preview_duration: é¢„è§ˆæ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            bool: æ¸²æŸ“æ˜¯å¦æˆåŠŸ
        """
        if not self.is_initialized or not self.freq_player:
            print("âŒ æ¸²æŸ“å™¨æˆ–é¢‘ç‡æ’­æ”¾å™¨æœªåˆå§‹åŒ–")
            return False
        
        try:
            print(f"ğŸ”Š å®æ—¶é¢„è§ˆ ({preview_duration}ç§’)...")
            
            # ç¡®ä¿SoundFontå·²åŠ è½½
            if not self._ensure_soundfont_loaded():
                return False
            
            # æå–é¢„è§ˆæ•°æ®
            preview_data = self._extract_preview_data(composition, preview_duration)
            
            # ä½¿ç”¨freq_playerè¿›è¡Œå®æ—¶æ’­æ”¾
            frequencies = [note["frequency"] for note in preview_data["notes"]]
            velocities = [note["velocity"] for note in preview_data["notes"]]
            durations = [note["duration"] for note in preview_data["notes"]]
            
            if frequencies:
                success_count = self.freq_player.play_accurate_sequence(
                    frequencies, velocities, durations,
                    show_progress=True
                )
                return success_count > 0
            else:
                print("âš ï¸ æ²¡æœ‰å¯æ’­æ”¾çš„éŸ³ç¬¦")
                return False
            
        except Exception as e:
            print(f"âŒ å®æ—¶æ¸²æŸ“å¤±è´¥: {e}")
            return False
    
    def _ensure_soundfont_loaded(self) -> bool:
        """ç¡®ä¿SoundFontå·²åŠ è½½"""
        if self.current_soundfont_id is not None:
            return True
        
        if not self.sf_manager:
            print("âŒ SoundFontç®¡ç†å™¨ä¸å¯ç”¨")
            return False
        
        # å°è¯•åŠ è½½é¦–é€‰SoundFont
        if hasattr(self.master_studio.config, 'preferred_soundfont'):
            preferred_sf = self.master_studio.config.preferred_soundfont
            if self.load_soundfont(preferred_sf):
                return True
        
        # å°è¯•è‡ªåŠ¨é€‰æ‹©æœ€ä½³SoundFont
        best_sf = self.sf_manager.get_best_soundfont_for_task("render")
        if best_sf and self.load_soundfont(best_sf):
            return True
        
        print("âŒ æ— æ³•åŠ è½½ä»»ä½•SoundFont")
        return False
    
    def _extract_composition_data(self, composition) -> Optional[Dict[str, Any]]:
        """
        ä»ä½œæ›²å¯¹è±¡æå–æ¸²æŸ“æ•°æ®
        
        Args:
            composition: ä½œæ›²å¯¹è±¡
            
        Returns:
            Dict: æ¸²æŸ“æ•°æ®ï¼ŒåŒ…å«éŸ³ç¬¦ã€æ—¶é—´ã€è¡¨ç°åŠ›ç­‰ä¿¡æ¯
        """
        try:
            render_data = {
                "notes": [],
                "total_duration": 0.0,
                "tempo": 120,  # é»˜è®¤BPM
                "measures": []
            }
            
            # æ£€æŸ¥ä½œæ›²å¯¹è±¡çš„æ¥å£
            if hasattr(composition, 'get_render_data'):
                # æ ‡å‡†æ¥å£
                return composition.get_render_data()
            
            elif hasattr(composition, 'bass_track') and hasattr(composition, 'chord_track'):
                # ä»è½¨é“æ•°æ®æå–
                render_data = self._extract_from_tracks(composition)
            
            elif hasattr(composition, 'get_all_notes'):
                # ä»éŸ³ç¬¦åˆ—è¡¨æå–
                notes = composition.get_all_notes()
                render_data["notes"] = self._convert_notes_to_render_format(notes)
            
            else:
                # å°è¯•é€šç”¨æ–¹æ³•
                print("âš ï¸ ä½œæ›²å¯¹è±¡æ¥å£æœªçŸ¥ï¼Œå°è¯•é€šç”¨æå–...")
                render_data = self._extract_generic(composition)
            
            return render_data if render_data["notes"] else None
            
        except Exception as e:
            print(f"âŒ ä½œæ›²æ•°æ®æå–å¤±è´¥: {e}")
            return None
    
    def _extract_from_tracks(self, composition) -> Dict[str, Any]:
        """ä»è½¨é“æ•°æ®æå–æ¸²æŸ“ä¿¡æ¯"""
        render_data = {
            "notes": [],
            "total_duration": 0.0,
            "tempo": getattr(composition, 'bpm', 120),
            "measures": []
        }
        
        # å¤„ç†ä½éŸ³è½¨é“
        if hasattr(composition, 'bass_track') and composition.bass_track:
            bass_notes = self._extract_track_notes(composition.bass_track, "bass")
            render_data["notes"].extend(bass_notes)
        
        # å¤„ç†å’Œå¼¦è½¨é“
        if hasattr(composition, 'chord_track') and composition.chord_track:
            chord_notes = self._extract_track_notes(composition.chord_track, "chord")
            render_data["notes"].extend(chord_notes)
        
        # å¤„ç†æ—‹å¾‹è½¨é“
        if hasattr(composition, 'melody_track') and composition.melody_track:
            melody_notes = self._extract_track_notes(composition.melody_track, "melody")
            render_data["notes"].extend(melody_notes)
        
        # è®¡ç®—æ€»æ—¶é•¿
        if render_data["notes"]:
            max_end_time = max(note["start_time"] + note["duration"] for note in render_data["notes"])
            render_data["total_duration"] = max_end_time
        
        return render_data
    
    def _extract_track_notes(self, track, track_type: str) -> List[Dict[str, Any]]:
        """ä»å•ä¸ªè½¨é“æå–éŸ³ç¬¦"""
        notes = []
        
        try:
            if hasattr(track, 'notes') and track.notes:
                for note_info in track.notes:
                    note_data = {
                        "frequency": getattr(note_info, 'frequency', 440.0),
                        "start_time": getattr(note_info, 'start_time', 0.0),
                        "duration": getattr(note_info, 'duration', 0.5),
                        "velocity": getattr(note_info, 'velocity', 80),
                        "track_type": track_type
                    }
                    notes.append(note_data)
            
        except Exception as e:
            print(f"âš ï¸ è½¨é“ {track_type} éŸ³ç¬¦æå–è­¦å‘Š: {e}")
        
        return notes
    
    def _convert_notes_to_render_format(self, notes) -> List[Dict[str, Any]]:
        """è½¬æ¢éŸ³ç¬¦åˆ°æ¸²æŸ“æ ¼å¼"""
        render_notes = []
        
        for note in notes:
            try:
                render_note = {
                    "frequency": getattr(note, 'frequency', 440.0),
                    "start_time": getattr(note, 'start_time', 0.0),
                    "duration": getattr(note, 'duration', 0.5),
                    "velocity": getattr(note, 'velocity', 80),
                    "track_type": getattr(note, 'track_type', 'unknown')
                }
                render_notes.append(render_note)
                
            except Exception as e:
                print(f"âš ï¸ éŸ³ç¬¦è½¬æ¢è­¦å‘Š: {e}")
                continue
        
        return render_notes
    
    def _extract_generic(self, composition) -> Dict[str, Any]:
        """é€šç”¨ä½œæ›²æ•°æ®æå–"""
        render_data = {
            "notes": [],
            "total_duration": 8.0,  # é»˜è®¤8ç§’
            "tempo": 120,
            "measures": []
        }
        
        # å°è¯•è·å–åŸºç¡€éŸ³é˜¶è¿›è¡Œæ¼”ç¤º
        if hasattr(composition, 'petersen_scale'):
            scale = composition.petersen_scale
            scale_entries = scale.get_scale_entries()[:8]  # å–å‰8ä¸ªéŸ³
            
            for i, entry in enumerate(scale_entries):
                note_data = {
                    "frequency": entry.freq,
                    "start_time": i * 0.8,  # æ¯ä¸ªéŸ³ç¬¦0.8ç§’é—´éš”
                    "duration": 0.6,
                    "velocity": 80,
                    "track_type": "scale_demo"
                }
                render_data["notes"].append(note_data)
        
        return render_data
    
    def _render_audio_data(self, render_data: Dict[str, Any]) -> Optional[np.ndarray]:
        """
        æ¸²æŸ“éŸ³é¢‘æ•°æ®
        
        Args:
            render_data: æ¸²æŸ“æ•°æ®
            
        Returns:
            numpy.ndarray: éŸ³é¢‘æ•°æ®æ•°ç»„
        """
        if not self.freq_player:
            return self._simulate_audio_data(render_data)
        
        try:
            # å‡†å¤‡æ¸²æŸ“
            notes = render_data["notes"]
            total_duration = render_data["total_duration"]
            sample_rate = self.current_settings.sample_rate
            
            # è®¡ç®—æ€»æ ·æœ¬æ•°
            total_samples = int(total_duration * sample_rate)
            
            # æ›´æ–°è¿›åº¦
            self.render_progress.total_notes = len(notes)
            self.render_progress.rendered_notes = 0
            
            print(f"   éŸ³ç¬¦æ•°é‡: {len(notes)}")
            print(f"   æ€»æ—¶é•¿: {total_duration:.1f}ç§’")
            print(f"   é‡‡æ ·ç‚¹: {total_samples:,}")
            
            # åˆ›å»ºéŸ³é¢‘ç¼“å†²åŒº
            if self.current_settings.bit_depth == 24:
                audio_buffer = np.zeros(total_samples, dtype=np.float32)
            else:
                audio_buffer = np.zeros(total_samples, dtype=np.int16)
            
            # æ¸²æŸ“æ¯ä¸ªéŸ³ç¬¦
            for i, note in enumerate(notes):
                if not self.is_rendering:  # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                    break
                
                self._render_single_note_with_freq_player(note, audio_buffer, sample_rate)
                
                self.render_progress.rendered_notes = i + 1
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 10 == 0 or (i + 1) == len(notes):
                    progress = (i + 1) / len(notes) * 100
                    print(f"   æ¸²æŸ“è¿›åº¦: {progress:.1f}% ({i + 1}/{len(notes)})")
            
            return audio_buffer
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•°æ®æ¸²æŸ“å¤±è´¥: {e}")
            return None
    
    def _render_single_note_with_freq_player(self, note: Dict[str, Any], 
                                           audio_buffer: np.ndarray, sample_rate: int):
        """ä½¿ç”¨freq_playeræ¸²æŸ“å•ä¸ªéŸ³ç¬¦åˆ°éŸ³é¢‘ç¼“å†²åŒº"""
        try:
            # è®¡ç®—æ—¶é—´å‚æ•°
            start_sample = int(note["start_time"] * sample_rate)
            duration_samples = int(note["duration"] * sample_rate)
            
            # ç¡®ä¿ä¸è¶…å‡ºç¼“å†²åŒº
            if start_sample >= len(audio_buffer):
                return
            
            end_sample = min(start_sample + duration_samples, len(audio_buffer))
            
            # ä½¿ç”¨freq_playerçš„ç²¾ç¡®é¢‘ç‡æ’­æ”¾åŠŸèƒ½
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„éŸ³é¢‘ç”Ÿæˆï¼Œè€Œä¸æ˜¯å®æ—¶æ’­æ”¾
            # æˆ‘ä»¬ä½¿ç”¨ç®€åŒ–çš„æ­£å¼¦æ³¢ç”Ÿæˆä½œä¸ºç¤ºä¾‹
            frequency = note["frequency"]
            amplitude = note["velocity"] / 127.0 * 0.1  # é™ä½éŸ³é‡
            
            # ç”Ÿæˆæ­£å¼¦æ³¢
            t = np.linspace(0, note["duration"], end_sample - start_sample)
            sine_wave = amplitude * np.sin(2 * np.pi * frequency * t)
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            if self.current_settings.bit_depth == 24:
                audio_buffer[start_sample:end_sample] += sine_wave.astype(np.float32)
            else:
                sine_wave_int = (sine_wave * (2**15 - 1)).astype(np.int16)
                audio_buffer[start_sample:end_sample] += sine_wave_int
            
        except Exception as e:
            print(f"âš ï¸ éŸ³ç¬¦æ¸²æŸ“è­¦å‘Š: {e}")
    
    def _simulate_audio_data(self, render_data: Dict[str, Any]) -> np.ndarray:
        """æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®ï¼ˆå½“freq_playerä¸å¯ç”¨æ—¶ï¼‰"""
        notes = render_data["notes"]
        total_duration = render_data["total_duration"]
        sample_rate = self.current_settings.sample_rate
        
        total_samples = int(total_duration * sample_rate)
        
        if self.current_settings.bit_depth == 24:
            audio_buffer = np.zeros(total_samples, dtype=np.float32)
        else:
            audio_buffer = np.zeros(total_samples, dtype=np.int16)
        
        print("   ä½¿ç”¨æ¨¡æ‹ŸéŸ³é¢‘æ¸²æŸ“...")
        
        # ä¸ºæ¯ä¸ªéŸ³ç¬¦ç”Ÿæˆç®€å•çš„æ­£å¼¦æ³¢
        for note in notes:
            frequency = note["frequency"]
            start_sample = int(note["start_time"] * sample_rate)
            duration_samples = int(note["duration"] * sample_rate)
            
            if start_sample >= len(audio_buffer):
                continue
            
            end_sample = min(start_sample + duration_samples, len(audio_buffer))
            
            # ç”Ÿæˆæ­£å¼¦æ³¢
            t = np.linspace(0, note["duration"], end_sample - start_sample)
            amplitude = note["velocity"] / 127.0 * 0.1  # é™ä½éŸ³é‡
            sine_wave = amplitude * np.sin(2 * np.pi * frequency * t)
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            if self.current_settings.bit_depth == 24:
                audio_buffer[start_sample:end_sample] += sine_wave.astype(np.float32)
            else:
                sine_wave_int = (sine_wave * (2**15 - 1)).astype(np.int16)
                audio_buffer[start_sample:end_sample] += sine_wave_int
        
        return audio_buffer
    
    def _normalize_audio(self, audio_data: np.ndarray) -> np.ndarray:
        """éŸ³é¢‘æ ‡å‡†åŒ–"""
        if len(audio_data) == 0:
            return audio_data
        
        # æ‰¾åˆ°å³°å€¼
        peak = np.max(np.abs(audio_data))
        
        if peak > 0:
            # æ ‡å‡†åŒ–åˆ°-1dBä»¥é¿å…å‰Šæ³¢
            if self.current_settings.bit_depth == 24:
                target_peak = 0.891  # çº¦-1dB (æµ®ç‚¹)
            else:
                target_peak = 0.891 * (2**15 - 1)  # çº¦-1dB (æ•´æ•°)
            
            audio_data = audio_data * (target_peak / peak)
        
        return audio_data
    
    def _apply_fade(self, audio_data: np.ndarray) -> np.ndarray:
        """åº”ç”¨æ·¡å…¥æ·¡å‡ºæ•ˆæœ"""
        if len(audio_data) == 0:
            return audio_data
        
        sample_rate = self.current_settings.sample_rate
        
        # æ·¡å…¥
        fade_in_samples = int(self.current_settings.fade_in_ms * sample_rate / 1000)
        if fade_in_samples > 0 and fade_in_samples < len(audio_data):
            fade_in = np.linspace(0, 1, fade_in_samples)
            audio_data[:fade_in_samples] *= fade_in
        
        # æ·¡å‡º
        fade_out_samples = int(self.current_settings.fade_out_ms * sample_rate / 1000)
        if fade_out_samples > 0 and fade_out_samples < len(audio_data):
            fade_out = np.linspace(1, 0, fade_out_samples)
            audio_data[-fade_out_samples:] *= fade_out
        
        return audio_data
    
    def _save_wav_file(self, audio_data: np.ndarray, output_path: Path) -> bool:
        """
        ä¿å­˜WAVæ–‡ä»¶
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # è½¬æ¢æ•°æ®æ ¼å¼
            if self.current_settings.bit_depth == 24:
                # 24ä½æµ®ç‚¹è½¬æ¢ä¸º24ä½æ•´æ•°
                if audio_data.dtype == np.float32:
                    audio_int = (audio_data * (2**23 - 1)).astype(np.int32)
                else:
                    audio_int = audio_data.astype(np.int32)
                sample_width = 3
            else:
                # 16ä½
                if audio_data.dtype == np.float32:
                    audio_int = (audio_data * (2**15 - 1)).astype(np.int16)
                else:
                    audio_int = audio_data.astype(np.int16)
                sample_width = 2
            
            # å†™å…¥WAVæ–‡ä»¶
            with wave.open(str(output_path), 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(sample_width)
                wav_file.setframerate(self.current_settings.sample_rate)
                
                if self.current_settings.bit_depth == 24:
                    # 24ä½éœ€è¦ç‰¹æ®Šå¤„ç†
                    audio_bytes = audio_int.tobytes()
                else:
                    audio_bytes = audio_int.tobytes()
                
                wav_file.writeframes(audio_bytes)
            
            return True
            
        except Exception as e:
            print(f"âŒ WAVæ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def _extract_preview_data(self, composition, duration: float) -> Dict[str, Any]:
        """æå–é¢„è§ˆæ•°æ®ï¼ˆæˆªå–å‰å‡ ç§’ï¼‰"""
        full_data = self._extract_composition_data(composition)
        
        if not full_data:
            return {"notes": [], "total_duration": 0.0}
        
        # è¿‡æ»¤å‡ºæŒ‡å®šæ—¶é•¿å†…çš„éŸ³ç¬¦
        preview_notes = [
            note for note in full_data["notes"]
            if note["start_time"] < duration
        ]
        
        # è°ƒæ•´éŸ³ç¬¦æ—¶é•¿
        for note in preview_notes:
            if note["start_time"] + note["duration"] > duration:
                note["duration"] = duration - note["start_time"]
        
        return {
            "notes": preview_notes,
            "total_duration": duration,
            "tempo": full_data.get("tempo", 120)
        }
    
    def get_render_progress(self) -> RenderProgress:
        """è·å–å½“å‰æ¸²æŸ“è¿›åº¦"""
        return self.render_progress
    
    def cancel_render(self):
        """å–æ¶ˆå½“å‰æ¸²æŸ“"""
        self.is_rendering = False
        self.render_progress.status = "å·²å–æ¶ˆ"
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # ä¸éœ€è¦æ¸…ç†FluidSynthèµ„æºï¼Œå› ä¸ºå®ƒä»¬å±äºmaster_studioçš„player
        self.is_initialized = False
        self.current_soundfont_id = None

# ========== ä¾¿åˆ©å‡½æ•° ==========

def create_studio_renderer(master_studio, quality: RenderQuality = RenderQuality.STANDARD) -> HighQualitySoundFontRenderer:
    """
    åˆ›å»ºå½•éŸ³å®¤çº§åˆ«æ¸²æŸ“å™¨
    
    Args:
        master_studio: PetersenMasterStudioå®ä¾‹
        quality: æ¸²æŸ“è´¨é‡
        
    Returns:
        HighQualitySoundFontRenderer: é…ç½®å¥½çš„æ¸²æŸ“å™¨
    """
    renderer = HighQualitySoundFontRenderer(master_studio)
    
    if renderer.is_initialized:
        renderer.configure_quality(quality)
    
    return renderer

def render_composition_to_wav(composition, output_path: str, 
                             master_studio, quality: str = "high") -> bool:
    """
    ä¾¿åˆ©å‡½æ•°ï¼šå°†ä½œæ›²æ¸²æŸ“ä¸ºWAVæ–‡ä»¶
    
    Args:
        composition: ä½œæ›²å¯¹è±¡
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        master_studio: PetersenMasterStudioå®ä¾‹
        quality: è´¨é‡çº§åˆ«å­—ç¬¦ä¸²
        
    Returns:
        bool: æ¸²æŸ“æ˜¯å¦æˆåŠŸ
    """
    quality_enum = RenderQuality(quality.lower())
    
    renderer = create_studio_renderer(master_studio, quality_enum)
    try:
        result_path = renderer.render_composition(composition, Path(output_path), quality_enum)
        return result_path is not None
    finally:
        renderer.cleanup()

if __name__ == "__main__":
    print("ğŸµ Petersené«˜è´¨é‡SoundFontæ¸²æŸ“å™¨")
    print("è¿™æ˜¯ä¸€ä¸ªæ”¯æŒæ¨¡å—ï¼Œè¯·é€šè¿‡PetersenMasterStudioä½¿ç”¨")