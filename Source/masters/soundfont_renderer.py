"""
é«˜è´¨é‡SoundFontæ¸²æŸ“å™¨

è´Ÿè´£å°†Petersenä½œæ›²è½¬æ¢ä¸ºé«˜è´¨é‡WAVéŸ³é¢‘æ–‡ä»¶ï¼Œè¿™æ˜¯æ•´ä¸ªç³»ç»Ÿæœ€ç»ˆè¾“å‡ºçš„æ ¸å¿ƒç»„ä»¶ã€‚
æ”¯æŒå½•éŸ³å®¤çº§åˆ«çš„éŸ³é¢‘æ¸²æŸ“ï¼Œç¡®ä¿æ•°å­¦æ¨¡å‹çš„éŸ³ä¹ç¾å­¦èƒ½å¤Ÿä»¥æœ€ä½³éŸ³è´¨å‘ˆç°ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- ç²¾ç¡®é¢‘ç‡SoundFontæ¸²æŸ“
- å¤šç§è´¨é‡çº§åˆ«æ”¯æŒ
- æ‰¹é‡éŸ³é¢‘ç”Ÿæˆ
- éŸ³æ•ˆå¤„ç†é“¾é›†æˆ
- å®æ—¶è¿›åº¦ç›‘æ§

æŠ€æœ¯ç‰¹ç‚¹ï¼š
- ä½¿ç”¨FluidSynthè¿›è¡Œä¸“ä¸šéŸ³é¢‘åˆæˆ
- æ”¯æŒ48kHz/24bitå½•éŸ³å®¤è´¨é‡
- ç²¾ç¡®çš„Petersené¢‘ç‡è¡¥å¿
- å®Œæ•´çš„éŸ³æ•ˆå¤„ç†æµæ°´çº¿
"""

import sys
import time
import wave
import array
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass
from enum import Enum

# å¯¼å…¥éŸ³é¢‘å¤„ç†åº“
try:
    import fluidsynth
    import numpy as np
    FLUIDSYNTH_AVAILABLE = True
except ImportError:
    FLUIDSYNTH_AVAILABLE = False
    print("âš ï¸ FluidSynthä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¸²æŸ“")

# æ·»åŠ libsè·¯å¾„
current_dir = Path(__file__).parent
libs_dir = current_dir.parent / "libs"
if str(libs_dir) not in sys.path:
    sys.path.insert(0, str(libs_dir))

try:
    from frequency_accurate import FrequencyAccuratePlayback
    from audio_effects import AdvancedAudioEffects, EffectSettings
    from expression_control import ExpressionController, ExpressionParameters
    from utils.constants import DEFAULT_SOUNDFONTS
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥éŸ³é¢‘æ¨¡å—å¤±è´¥: {e}")

class RenderQuality(Enum):
    """æ¸²æŸ“è´¨é‡çº§åˆ«"""
    DRAFT = "draft"           # 22kHz, 16bit, åŸºç¡€éŸ³æ•ˆ
    STANDARD = "standard"     # 44.1kHz, 16bit, æ ‡å‡†éŸ³æ•ˆ
    HIGH = "high"            # 44.1kHz, 24bit, é«˜çº§éŸ³æ•ˆ
    STUDIO = "studio"        # 48kHz, 24bit, å½•éŸ³å®¤éŸ³æ•ˆ

@dataclass
class RenderSettings:
    """æ¸²æŸ“è®¾ç½®"""
    quality: RenderQuality = RenderQuality.STANDARD
    sample_rate: int = 44100
    bit_depth: int = 16
    buffer_size: int = 512
    enable_effects: bool = True
    enable_expression: bool = True
    normalize_audio: bool = True
    fade_in_ms: int = 50
    fade_out_ms: int = 200

@dataclass
class RenderProgress:
    """æ¸²æŸ“è¿›åº¦"""
    total_notes: int = 0
    rendered_notes: int = 0
    current_measure: int = 0
    total_measures: int = 0
    elapsed_time: float = 0.0
    estimated_remaining: float = 0.0
    status: str = "å‡†å¤‡ä¸­"

class HighQualitySoundFontRenderer:
    """é«˜è´¨é‡SoundFontæ¸²æŸ“å™¨"""
    
    def __init__(self, master_studio):
        """
        åˆå§‹åŒ–æ¸²æŸ“å™¨
        
        Args:
            master_studio: PetersenMasterStudioå®ä¾‹
        """
        self.master_studio = master_studio
        
        # æ¸²æŸ“ç»„ä»¶
        self.fluidsynth_lib = None
        self.synth = None
        self.current_soundfont_id = None
        
        # æ¸²æŸ“çŠ¶æ€
        self.is_initialized = False
        self.current_settings = RenderSettings()
        self.render_progress = RenderProgress()
        self.is_rendering = False
        
        # éŸ³é¢‘ç¼“å†²
        self.audio_buffer = []
        self.buffer_lock = threading.Lock()
        
        # åˆå§‹åŒ–æ¸²æŸ“å™¨
        self._initialize_renderer()
    
    def _initialize_renderer(self):
        """åˆå§‹åŒ–æ¸²æŸ“å™¨"""
        try:
            if not FLUIDSYNTH_AVAILABLE:
                print("âš ï¸ FluidSynthä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self.is_initialized = False
                return
            
            # åˆå§‹åŒ–FluidSynth
            self.fluidsynth_lib = fluidsynth
            self.synth = fluidsynth.Synth()
            
            # è®¾ç½®é»˜è®¤å‚æ•°
            self.synth.setting('audio.sample-format', '16bits')
            self.synth.setting('audio.buffer-size', str(self.current_settings.buffer_size))
            
            # å¯åŠ¨éŸ³é¢‘é©±åŠ¨
            self.synth.start()
            
            self.is_initialized = True
            print("âœ“ é«˜è´¨é‡æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¸²æŸ“å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_initialized = False
    
    def load_soundfont(self, soundfont_path: str) -> bool:
        """
        åŠ è½½SoundFontæ–‡ä»¶
        
        Args:
            soundfont_path: SoundFontæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        if not self.is_initialized:
            return False
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            sf_path = Path(soundfont_path)
            if not sf_path.exists():
                # å°è¯•åœ¨é…ç½®çš„SoundFontç›®å½•ä¸­æŸ¥æ‰¾
                sf_dir = self.master_studio.config.soundfont_directory
                sf_path = sf_dir / soundfont_path
                
                if not sf_path.exists():
                    print(f"âŒ SoundFontæ–‡ä»¶ä¸å­˜åœ¨: {soundfont_path}")
                    return False
            
            # å¸è½½å½“å‰SoundFont
            if self.current_soundfont_id is not None:
                self.synth.sfunload(self.current_soundfont_id)
            
            # åŠ è½½æ–°SoundFont
            self.current_soundfont_id = self.synth.sfload(str(sf_path))
            
            if self.current_soundfont_id != -1:
                # è®¾ç½®ç¨‹åº
                self.synth.program_select(0, self.current_soundfont_id, 0, 0)
                print(f"âœ“ SoundFontå·²åŠ è½½: {sf_path.name}")
                return True
            else:
                print(f"âŒ SoundFontåŠ è½½å¤±è´¥: {sf_path}")
                return False
                
        except Exception as e:
            print(f"âŒ SoundFontåŠ è½½é”™è¯¯: {e}")
            return False
    
    def configure_quality(self, quality: RenderQuality):
        """
        é…ç½®æ¸²æŸ“è´¨é‡
        
        Args:
            quality: è´¨é‡çº§åˆ«
        """
        quality_settings = {
            RenderQuality.DRAFT: RenderSettings(
                quality=quality,
                sample_rate=22050,
                bit_depth=16,
                buffer_size=1024,
                enable_effects=False,
                enable_expression=False
            ),
            RenderQuality.STANDARD: RenderSettings(
                quality=quality,
                sample_rate=44100,
                bit_depth=16,
                buffer_size=512,
                enable_effects=True,
                enable_expression=True
            ),
            RenderQuality.HIGH: RenderSettings(
                quality=quality,
                sample_rate=44100,
                bit_depth=24,
                buffer_size=256,
                enable_effects=True,
                enable_expression=True
            ),
            RenderQuality.STUDIO: RenderSettings(
                quality=quality,
                sample_rate=48000,
                bit_depth=24,
                buffer_size=128,
                enable_effects=True,
                enable_expression=True,
                normalize_audio=True
            )
        }
        
        self.current_settings = quality_settings[quality]
        
        # æ›´æ–°FluidSynthè®¾ç½®
        if self.is_initialized:
            try:
                self.synth.setting('synth.sample-rate', str(self.current_settings.sample_rate))
                
                if self.current_settings.bit_depth == 24:
                    self.synth.setting('audio.sample-format', 'float')
                else:
                    self.synth.setting('audio.sample-format', '16bits')
                
                print(f"âœ“ æ¸²æŸ“è´¨é‡å·²è®¾ç½®ä¸º: {quality.value}")
                print(f"   é‡‡æ ·ç‡: {self.current_settings.sample_rate}Hz")
                print(f"   ä½æ·±åº¦: {self.current_settings.bit_depth}bit")
                
            except Exception as e:
                print(f"âš ï¸ è´¨é‡è®¾ç½®æ›´æ–°è­¦å‘Š: {e}")
    
    def render_composition(self, composition, output_path: Path, 
                          quality: Optional[RenderQuality] = None) -> Optional[Path]:
        """
        æ¸²æŸ“å®Œæ•´ä½œæ›²åˆ°WAVæ–‡ä»¶
        
        Args:
            composition: ä½œæ›²å¯¹è±¡
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            quality: æ¸²æŸ“è´¨é‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Path: æˆåŠŸæ—¶è¿”å›è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.is_initialized:
            print("âŒ æ¸²æŸ“å™¨æœªåˆå§‹åŒ–")
            return None
        
        try:
            # è®¾ç½®è´¨é‡
            if quality:
                self.configure_quality(quality)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¼€å§‹æ¸²æŸ“
            self.is_rendering = True
            self.render_progress.status = "æ­£åœ¨æ¸²æŸ“..."
            
            print(f"ğŸµ å¼€å§‹æ¸²æŸ“: {output_path.name}")
            print(f"   è´¨é‡: {self.current_settings.quality.value}")
            
            # åŠ è½½é¦–é€‰SoundFont
            if not self._ensure_soundfont_loaded():
                return None
            
            # æå–ä½œæ›²æ•°æ®
            render_data = self._extract_composition_data(composition)
            if not render_data:
                print("âŒ æ— æ³•æå–ä½œæ›²æ•°æ®")
                return None
            
            # æ‰§è¡Œæ¸²æŸ“
            audio_data = self._render_audio_data(render_data)
            if not audio_data:
                print("âŒ éŸ³é¢‘æ¸²æŸ“å¤±è´¥")
                return None
            
            # åå¤„ç†
            if self.current_settings.normalize_audio:
                audio_data = self._normalize_audio(audio_data)
            
            audio_data = self._apply_fade(audio_data)
            
            # ä¿å­˜WAVæ–‡ä»¶
            success = self._save_wav_file(audio_data, output_path)
            
            if success:
                print(f"âœ“ æ¸²æŸ“å®Œæˆ: {output_path.name}")
                print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.1f} MB")
                return output_path
            else:
                return None
                
        except Exception as e:
            print(f"âŒ æ¸²æŸ“å¤±è´¥: {e}")
            return None
        finally:
            self.is_rendering = False
            self.render_progress.status = "å®Œæˆ"
    
    def render_composition_realtime(self, composition, preview_duration: float = 10.0) -> bool:
        """
        å®æ—¶æ¸²æŸ“ä½œæ›²é¢„è§ˆ
        
        Args:
            composition: ä½œæ›²å¯¹è±¡
            preview_duration: é¢„è§ˆæ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            bool: æ¸²æŸ“æ˜¯å¦æˆåŠŸ
        """
        if not self.is_initialized:
            print("âŒ æ¸²æŸ“å™¨æœªåˆå§‹åŒ–")
            return False
        
        try:
            print(f"ğŸ”Š å®æ—¶é¢„è§ˆ ({preview_duration}ç§’)...")
            
            # ç¡®ä¿SoundFontå·²åŠ è½½
            if not self._ensure_soundfont_loaded():
                return False
            
            # æå–é¢„è§ˆæ•°æ®
            preview_data = self._extract_preview_data(composition, preview_duration)
            
            # å®æ—¶æ’­æ”¾
            return self._play_realtime(preview_data)
            
        except Exception as e:
            print(f"âŒ å®æ—¶æ¸²æŸ“å¤±è´¥: {e}")
            return False
    
    def _ensure_soundfont_loaded(self) -> bool:
        """ç¡®ä¿SoundFontå·²åŠ è½½"""
        if self.current_soundfont_id is not None:
            return True
        
        # å°è¯•åŠ è½½é¦–é€‰SoundFont
        preferred_sf = self.master_studio.config.preferred_soundfont
        if self.load_soundfont(preferred_sf):
            return True
        
        # å°è¯•å¤‡é€‰SoundFont
        alternative_sf = self.master_studio.config.alternative_soundfont
        if self.load_soundfont(alternative_sf):
            return True
        
        print("âŒ æ— æ³•åŠ è½½ä»»ä½•SoundFont")
        return False
    
    def _extract_composition_data(self, composition) -> Optional[Dict[str, Any]]:
        """
        ä»ä½œæ›²å¯¹è±¡æå–æ¸²æŸ“æ•°æ®
        
        Args:
            composition: ä½œæ›²å¯¹è±¡
            
        Returns:
            Dict: æ¸²æŸ“æ•°æ®ï¼ŒåŒ…å«éŸ³ç¬¦ã€æ—¶é—´ã€è¡¨ç°åŠ›ç­‰ä¿¡æ¯
        """
        try:
            render_data = {
                "notes": [],
                "total_duration": 0.0,
                "tempo": 120,  # é»˜è®¤BPM
                "measures": []
            }
            
            # æ£€æŸ¥ä½œæ›²å¯¹è±¡çš„æ¥å£
            if hasattr(composition, 'get_render_data'):
                # æ ‡å‡†æ¥å£
                return composition.get_render_data()
            
            elif hasattr(composition, 'bass_track') and hasattr(composition, 'chord_track'):
                # ä»è½¨é“æ•°æ®æå–
                render_data = self._extract_from_tracks(composition)
            
            elif hasattr(composition, 'get_all_notes'):
                # ä»éŸ³ç¬¦åˆ—è¡¨æå–
                notes = composition.get_all_notes()
                render_data["notes"] = self._convert_notes_to_render_format(notes)
            
            else:
                # å°è¯•é€šç”¨æ–¹æ³•
                print("âš ï¸ ä½œæ›²å¯¹è±¡æ¥å£æœªçŸ¥ï¼Œå°è¯•é€šç”¨æå–...")
                render_data = self._extract_generic(composition)
            
            return render_data if render_data["notes"] else None
            
        except Exception as e:
            print(f"âŒ ä½œæ›²æ•°æ®æå–å¤±è´¥: {e}")
            return None
    
    def _extract_from_tracks(self, composition) -> Dict[str, Any]:
        """ä»è½¨é“æ•°æ®æå–æ¸²æŸ“ä¿¡æ¯"""
        render_data = {
            "notes": [],
            "total_duration": 0.0,
            "tempo": getattr(composition, 'bpm', 120),
            "measures": []
        }
        
        # å¤„ç†ä½éŸ³è½¨é“
        if hasattr(composition, 'bass_track') and composition.bass_track:
            bass_notes = self._extract_track_notes(composition.bass_track, "bass")
            render_data["notes"].extend(bass_notes)
        
        # å¤„ç†å’Œå¼¦è½¨é“
        if hasattr(composition, 'chord_track') and composition.chord_track:
            chord_notes = self._extract_track_notes(composition.chord_track, "chord")
            render_data["notes"].extend(chord_notes)
        
        # å¤„ç†æ—‹å¾‹è½¨é“
        if hasattr(composition, 'melody_track') and composition.melody_track:
            melody_notes = self._extract_track_notes(composition.melody_track, "melody")
            render_data["notes"].extend(melody_notes)
        
        # è®¡ç®—æ€»æ—¶é•¿
        if render_data["notes"]:
            max_end_time = max(note["start_time"] + note["duration"] for note in render_data["notes"])
            render_data["total_duration"] = max_end_time
        
        return render_data
    
    def _extract_track_notes(self, track, track_type: str) -> List[Dict[str, Any]]:
        """ä»å•ä¸ªè½¨é“æå–éŸ³ç¬¦"""
        notes = []
        
        try:
            if hasattr(track, 'notes') and track.notes:
                for note_info in track.notes:
                    note_data = {
                        "frequency": getattr(note_info, 'frequency', 440.0),
                        "start_time": getattr(note_info, 'start_time', 0.0),
                        "duration": getattr(note_info, 'duration', 0.5),
                        "velocity": getattr(note_info, 'velocity', 80),
                        "track_type": track_type
                    }
                    notes.append(note_data)
            
        except Exception as e:
            print(f"âš ï¸ è½¨é“ {track_type} éŸ³ç¬¦æå–è­¦å‘Š: {e}")
        
        return notes
    
    def _convert_notes_to_render_format(self, notes) -> List[Dict[str, Any]]:
        """è½¬æ¢éŸ³ç¬¦åˆ°æ¸²æŸ“æ ¼å¼"""
        render_notes = []
        
        for note in notes:
            try:
                render_note = {
                    "frequency": getattr(note, 'frequency', 440.0),
                    "start_time": getattr(note, 'start_time', 0.0),
                    "duration": getattr(note, 'duration', 0.5),
                    "velocity": getattr(note, 'velocity', 80),
                    "track_type": getattr(note, 'track_type', 'unknown')
                }
                render_notes.append(render_note)
                
            except Exception as e:
                print(f"âš ï¸ éŸ³ç¬¦è½¬æ¢è­¦å‘Š: {e}")
                continue
        
        return render_notes
    
    def _extract_generic(self, composition) -> Dict[str, Any]:
        """é€šç”¨ä½œæ›²æ•°æ®æå–"""
        render_data = {
            "notes": [],
            "total_duration": 8.0,  # é»˜è®¤8ç§’
            "tempo": 120,
            "measures": []
        }
        
        # å°è¯•è·å–åŸºç¡€éŸ³é˜¶è¿›è¡Œæ¼”ç¤º
        if hasattr(composition, 'petersen_scale'):
            scale = composition.petersen_scale
            scale_entries = scale.get_scale_entries()[:8]  # å–å‰8ä¸ªéŸ³
            
            for i, entry in enumerate(scale_entries):
                note_data = {
                    "frequency": entry.freq,
                    "start_time": i * 0.8,  # æ¯ä¸ªéŸ³ç¬¦0.8ç§’é—´éš”
                    "duration": 0.6,
                    "velocity": 80,
                    "track_type": "scale_demo"
                }
                render_data["notes"].append(note_data)
        
        return render_data
    
    def _render_audio_data(self, render_data: Dict[str, Any]) -> Optional[np.ndarray]:
        """
        æ¸²æŸ“éŸ³é¢‘æ•°æ®
        
        Args:
            render_data: æ¸²æŸ“æ•°æ®
            
        Returns:
            numpy.ndarray: éŸ³é¢‘æ•°æ®æ•°ç»„
        """
        if not FLUIDSYNTH_AVAILABLE:
            return self._simulate_audio_data(render_data)
        
        try:
            # å‡†å¤‡æ¸²æŸ“
            notes = render_data["notes"]
            total_duration = render_data["total_duration"]
            sample_rate = self.current_settings.sample_rate
            
            # è®¡ç®—æ€»æ ·æœ¬æ•°
            total_samples = int(total_duration * sample_rate)
            
            # æ›´æ–°è¿›åº¦
            self.render_progress.total_notes = len(notes)
            self.render_progress.rendered_notes = 0
            
            print(f"   éŸ³ç¬¦æ•°é‡: {len(notes)}")
            print(f"   æ€»æ—¶é•¿: {total_duration:.1f}ç§’")
            print(f"   é‡‡æ ·ç‚¹: {total_samples:,}")
            
            # åˆ›å»ºéŸ³é¢‘ç¼“å†²åŒº
            if self.current_settings.bit_depth == 24:
                audio_buffer = np.zeros(total_samples, dtype=np.float32)
            else:
                audio_buffer = np.zeros(total_samples, dtype=np.int16)
            
            # æ¸²æŸ“æ¯ä¸ªéŸ³ç¬¦
            for i, note in enumerate(notes):
                if not self.is_rendering:  # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                    break
                
                self._render_single_note(note, audio_buffer, sample_rate)
                
                self.render_progress.rendered_notes = i + 1
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 10 == 0 or (i + 1) == len(notes):
                    progress = (i + 1) / len(notes) * 100
                    print(f"   æ¸²æŸ“è¿›åº¦: {progress:.1f}% ({i + 1}/{len(notes)})")
            
            return audio_buffer
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•°æ®æ¸²æŸ“å¤±è´¥: {e}")
            return None
    
    def _render_single_note(self, note: Dict[str, Any], audio_buffer: np.ndarray, sample_rate: int):
        """æ¸²æŸ“å•ä¸ªéŸ³ç¬¦åˆ°éŸ³é¢‘ç¼“å†²åŒº"""
        try:
            # è®¡ç®—MIDIéŸ³ç¬¦å·å’Œå¼¯éŸ³è½®å€¼
            frequency = note["frequency"]
            midi_note, pitch_bend = self._frequency_to_midi_with_bend(frequency)
            
            # è®¡ç®—æ—¶é—´å‚æ•°
            start_sample = int(note["start_time"] * sample_rate)
            duration_samples = int(note["duration"] * sample_rate)
            
            # ç¡®ä¿ä¸è¶…å‡ºç¼“å†²åŒº
            if start_sample >= len(audio_buffer):
                return
            
            end_sample = min(start_sample + duration_samples, len(audio_buffer))
            actual_duration = (end_sample - start_sample) / sample_rate
            
            # è®¾ç½®å¼¯éŸ³è½®
            if pitch_bend != 8192:  # éä¸­æ€§å€¼
                self.synth.pitch_bend(0, pitch_bend)
            
            # å¼€å§‹éŸ³ç¬¦
            self.synth.noteon(0, midi_note, note["velocity"])
            
            # æ¸²æŸ“è¿™ä¸ªéŸ³ç¬¦çš„éŸ³é¢‘æ®µ
            note_samples = end_sample - start_sample
            if note_samples > 0:
                # ç”ŸæˆéŸ³é¢‘
                note_audio = self.synth.get_samples(note_samples)
                
                if note_audio is not None and len(note_audio) == note_samples:
                    # æ·»åŠ åˆ°ä¸»ç¼“å†²åŒº
                    audio_buffer[start_sample:end_sample] += note_audio
            
            # åœæ­¢éŸ³ç¬¦
            self.synth.noteoff(0, midi_note)
            
            # é‡ç½®å¼¯éŸ³è½®
            if pitch_bend != 8192:
                self.synth.pitch_bend(0, 8192)
            
        except Exception as e:
            print(f"âš ï¸ éŸ³ç¬¦æ¸²æŸ“è­¦å‘Š: {e}")
    
    def _frequency_to_midi_with_bend(self, frequency: float) -> Tuple[int, int]:
        """
        å°†é¢‘ç‡è½¬æ¢ä¸ºMIDIéŸ³ç¬¦å·å’Œå¼¯éŸ³è½®å€¼
        
        Args:
            frequency: é¢‘ç‡(Hz)
            
        Returns:
            Tuple[int, int]: (MIDIéŸ³ç¬¦å·, å¼¯éŸ³è½®å€¼)
        """
        # è®¡ç®—æœ€æ¥è¿‘çš„MIDIéŸ³ç¬¦
        midi_note_float = 69 + 12 * np.log2(frequency / 440.0)
        midi_note = int(round(midi_note_float))
        
        # è®¡ç®—éŸ³åˆ†å·®å¼‚
        midi_freq = 440.0 * (2 ** ((midi_note - 69) / 12))
        cents_diff = 1200 * np.log2(frequency / midi_freq)
        
        # è½¬æ¢ä¸ºå¼¯éŸ³è½®å€¼ (èŒƒå›´: 0-16383, ä¸­æ€§å€¼: 8192)
        # å¼¯éŸ³è½®èŒƒå›´é€šå¸¸æ˜¯Â±200éŸ³åˆ†
        bend_range = 200.0  # éŸ³åˆ†
        pitch_bend = 8192 + int((cents_diff / bend_range) * 8192)
        
        # é™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…
        pitch_bend = max(0, min(16383, pitch_bend))
        
        return midi_note, pitch_bend
    
    def _simulate_audio_data(self, render_data: Dict[str, Any]) -> np.ndarray:
        """æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®ï¼ˆå½“FluidSynthä¸å¯ç”¨æ—¶ï¼‰"""
        notes = render_data["notes"]
        total_duration = render_data["total_duration"]
        sample_rate = self.current_settings.sample_rate
        
        total_samples = int(total_duration * sample_rate)
        audio_buffer = np.zeros(total_samples, dtype=np.float32)
        
        print("   ä½¿ç”¨æ¨¡æ‹ŸéŸ³é¢‘æ¸²æŸ“...")
        
        # ä¸ºæ¯ä¸ªéŸ³ç¬¦ç”Ÿæˆç®€å•çš„æ­£å¼¦æ³¢
        for note in notes:
            frequency = note["frequency"]
            start_sample = int(note["start_time"] * sample_rate)
            duration_samples = int(note["duration"] * sample_rate)
            
            if start_sample >= len(audio_buffer):
                continue
            
            end_sample = min(start_sample + duration_samples, len(audio_buffer))
            
            # ç”Ÿæˆæ­£å¼¦æ³¢
            t = np.linspace(0, note["duration"], end_sample - start_sample)
            amplitude = note["velocity"] / 127.0 * 0.1  # é™ä½éŸ³é‡
            sine_wave = amplitude * np.sin(2 * np.pi * frequency * t)
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            audio_buffer[start_sample:end_sample] += sine_wave
        
        return audio_buffer
    
    def _normalize_audio(self, audio_data: np.ndarray) -> np.ndarray:
        """éŸ³é¢‘æ ‡å‡†åŒ–"""
        if len(audio_data) == 0:
            return audio_data
        
        # æ‰¾åˆ°å³°å€¼
        peak = np.max(np.abs(audio_data))
        
        if peak > 0:
            # æ ‡å‡†åŒ–åˆ°-1dBä»¥é¿å…å‰Šæ³¢
            target_peak = 0.891  # çº¦-1dB
            audio_data = audio_data * (target_peak / peak)
        
        return audio_data
    
    def _apply_fade(self, audio_data: np.ndarray) -> np.ndarray:
        """åº”ç”¨æ·¡å…¥æ·¡å‡ºæ•ˆæœ"""
        if len(audio_data) == 0:
            return audio_data
        
        sample_rate = self.current_settings.sample_rate
        
        # æ·¡å…¥
        fade_in_samples = int(self.current_settings.fade_in_ms * sample_rate / 1000)
        if fade_in_samples > 0 and fade_in_samples < len(audio_data):
            fade_in = np.linspace(0, 1, fade_in_samples)
            audio_data[:fade_in_samples] *= fade_in
        
        # æ·¡å‡º
        fade_out_samples = int(self.current_settings.fade_out_ms * sample_rate / 1000)
        if fade_out_samples > 0 and fade_out_samples < len(audio_data):
            fade_out = np.linspace(1, 0, fade_out_samples)
            audio_data[-fade_out_samples:] *= fade_out
        
        return audio_data
    
    def _save_wav_file(self, audio_data: np.ndarray, output_path: Path) -> bool:
        """
        ä¿å­˜WAVæ–‡ä»¶
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # è½¬æ¢æ•°æ®æ ¼å¼
            if self.current_settings.bit_depth == 24:
                # 24ä½æµ®ç‚¹è½¬æ¢ä¸º24ä½æ•´æ•°
                audio_int = (audio_data * (2**23 - 1)).astype(np.int32)
                sample_width = 3
            else:
                # 16ä½
                audio_int = (audio_data * (2**15 - 1)).astype(np.int16)
                sample_width = 2
            
            # å†™å…¥WAVæ–‡ä»¶
            with wave.open(str(output_path), 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(sample_width)
                wav_file.setframerate(self.current_settings.sample_rate)
                
                if self.current_settings.bit_depth == 24:
                    # 24ä½éœ€è¦ç‰¹æ®Šå¤„ç†
                    audio_bytes = audio_int.tobytes()
                else:
                    audio_bytes = audio_int.tobytes()
                
                wav_file.writeframes(audio_bytes)
            
            return True
            
        except Exception as e:
            print(f"âŒ WAVæ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def _extract_preview_data(self, composition, duration: float) -> Dict[str, Any]:
        """æå–é¢„è§ˆæ•°æ®ï¼ˆæˆªå–å‰å‡ ç§’ï¼‰"""
        full_data = self._extract_composition_data(composition)
        
        if not full_data:
            return {"notes": [], "total_duration": 0.0}
        
        # è¿‡æ»¤å‡ºæŒ‡å®šæ—¶é•¿å†…çš„éŸ³ç¬¦
        preview_notes = [
            note for note in full_data["notes"]
            if note["start_time"] < duration
        ]
        
        # è°ƒæ•´éŸ³ç¬¦æ—¶é•¿
        for note in preview_notes:
            if note["start_time"] + note["duration"] > duration:
                note["duration"] = duration - note["start_time"]
        
        return {
            "notes": preview_notes,
            "total_duration": duration,
            "tempo": full_data.get("tempo", 120)
        }
    
    def _play_realtime(self, preview_data: Dict[str, Any]) -> bool:
        """å®æ—¶æ’­æ”¾é¢„è§ˆæ•°æ®"""
        if not FLUIDSYNTH_AVAILABLE:
            print("âš ï¸ FluidSynthä¸å¯ç”¨ï¼Œè·³è¿‡å®æ—¶æ’­æ”¾")
            return False
        
        try:
            notes = preview_data["notes"]
            
            # æŒ‰å¼€å§‹æ—¶é—´æ’åº
            notes.sort(key=lambda x: x["start_time"])
            
            start_time = time.time()
            
            for note in notes:
                # ç­‰å¾…åˆ°éŸ³ç¬¦å¼€å§‹æ—¶é—´
                target_time = start_time + note["start_time"]
                current_time = time.time()
                
                if target_time > current_time:
                    time.sleep(target_time - current_time)
                
                # è®¡ç®—MIDIå‚æ•°
                midi_note, pitch_bend = self._frequency_to_midi_with_bend(note["frequency"])
                
                # è®¾ç½®å¼¯éŸ³è½®
                if pitch_bend != 8192:
                    self.synth.pitch_bend(0, pitch_bend)
                
                # æ’­æ”¾éŸ³ç¬¦
                self.synth.noteon(0, midi_note, note["velocity"])
                
                # ç­‰å¾…éŸ³ç¬¦æ—¶é•¿
                time.sleep(note["duration"])
                
                # åœæ­¢éŸ³ç¬¦
                self.synth.noteoff(0, midi_note)
                
                # é‡ç½®å¼¯éŸ³è½®
                if pitch_bend != 8192:
                    self.synth.pitch_bend(0, 8192)
            
            return True
            
        except Exception as e:
            print(f"âŒ å®æ—¶æ’­æ”¾å¤±è´¥: {e}")
            return False
    
    def get_render_progress(self) -> RenderProgress:
        """è·å–å½“å‰æ¸²æŸ“è¿›åº¦"""
        return self.render_progress
    
    def cancel_render(self):
        """å–æ¶ˆå½“å‰æ¸²æŸ“"""
        self.is_rendering = False
        self.render_progress.status = "å·²å–æ¶ˆ"
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.synth:
            try:
                self.synth.delete()
            except:
                pass
        
        self.is_initialized = False
        self.current_soundfont_id = None

# ========== ä¾¿åˆ©å‡½æ•° ==========

def create_studio_renderer(master_studio, quality: RenderQuality = RenderQuality.STANDARD) -> HighQualitySoundFontRenderer:
    """
    åˆ›å»ºå½•éŸ³å®¤çº§åˆ«æ¸²æŸ“å™¨
    
    Args:
        master_studio: PetersenMasterStudioå®ä¾‹
        quality: æ¸²æŸ“è´¨é‡
        
    Returns:
        HighQualitySoundFontRenderer: é…ç½®å¥½çš„æ¸²æŸ“å™¨
    """
    renderer = HighQualitySoundFontRenderer(master_studio)
    
    if renderer.is_initialized:
        renderer.configure_quality(quality)
    
    return renderer

def render_composition_to_wav(composition, output_path: str, 
                             master_studio, quality: str = "high") -> bool:
    """
    ä¾¿åˆ©å‡½æ•°ï¼šå°†ä½œæ›²æ¸²æŸ“ä¸ºWAVæ–‡ä»¶
    
    Args:
        composition: ä½œæ›²å¯¹è±¡
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        master_studio: PetersenMasterStudioå®ä¾‹
        quality: è´¨é‡çº§åˆ«å­—ç¬¦ä¸²
        
    Returns:
        bool: æ¸²æŸ“æ˜¯å¦æˆåŠŸ
    """
    quality_enum = RenderQuality(quality.lower())
    
    with create_studio_renderer(master_studio, quality_enum) as renderer:
        result_path = renderer.render_composition(composition, Path(output_path), quality_enum)
        return result_path is not None

if __name__ == "__main__":
    print("ğŸµ Petersené«˜è´¨é‡SoundFontæ¸²æŸ“å™¨")
    print("è¿™æ˜¯ä¸€ä¸ªæ”¯æŒæ¨¡å—ï¼Œè¯·é€šè¿‡PetersenMasterStudioä½¿ç”¨")